#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Model Manager - L∆∞u, T·∫£i v√† D·ª± ƒëo√°n v·ªõi M√¥ h√¨nh ML
Author: AI Assistant
Date: 2025-11-03
"""

import joblib
import pickle
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.preprocessing import OneHotEncoder
from scipy.stats import boxcox
import warnings
warnings.filterwarnings('ignore')


class ModelManager:
    """
    Class qu·∫£n l√Ω vi·ªác l∆∞u, t·∫£i v√† d·ª± ƒëo√°n v·ªõi m√¥ h√¨nh machine learning
    """
    
    def __init__(self, model_dir="../../models"):
        """
        Kh·ªüi t·∫°o ModelManager
        
        Parameters:
        -----------
        model_dir : str
            Th∆∞ m·ª•c l∆∞u tr·ªØ m√¥ h√¨nh (relative to scripts folder)
        """
        # Get absolute path from current script location
        script_dir = Path(__file__).parent
        self.model_dir = (script_dir / model_dir).resolve()
        self.model_dir.mkdir(parents=True, exist_ok=True)
        
        self.model = None
        self.ohe = None
        self.fitted_lambda = None
        self.product_target_mean = None
        self.overall_mean = None
    
    
    def save_model_pickle(self, model, filename="model.pkl"):
        """
        L∆∞u m√¥ h√¨nh b·∫±ng pickle
        
        Parameters:
        -----------
        model : object
            M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán
        filename : str
            T√™n file ƒë·ªÉ l∆∞u
        """
        filepath = self.model_dir / filename
        with open(filepath, 'wb') as f:
            pickle.dump(model, f)
        print(f"‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh b·∫±ng pickle t·∫°i: {filepath}")
    
    
    def load_model_pickle(self, filename="model.pkl"):
        """
        T·∫£i m√¥ h√¨nh t·ª´ file pickle
        
        Parameters:
        -----------
        filename : str
            T√™n file c·∫ßn t·∫£i
            
        Returns:
        --------
        model : object
            M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c t·∫£i
        """
        filepath = self.model_dir / filename
        with open(filepath, 'rb') as f:
            model = pickle.load(f)
        print(f"‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh t·ª´: {filepath}")
        return model
    
    
    def save_model_joblib(self, model, filename="model.joblib"):
        """
        L∆∞u m√¥ h√¨nh b·∫±ng joblib (KHUY√äN D√ôNG cho Scikit-learn)
        
        Parameters:
        -----------
        model : object
            M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán
        filename : str
            T√™n file ƒë·ªÉ l∆∞u
        """
        filepath = self.model_dir / filename
        joblib.dump(model, filepath)
        print(f"‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh b·∫±ng joblib t·∫°i: {filepath}")
    
    
    def load_model_joblib(self, filename="model.joblib"):
        """
        T·∫£i m√¥ h√¨nh t·ª´ file joblib
        
        Parameters:
        -----------
        filename : str
            T√™n file c·∫ßn t·∫£i
            
        Returns:
        --------
        model : object
            M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c t·∫£i
        """
        filepath = self.model_dir / filename
        model = joblib.load(filepath)
        print(f"‚úÖ ƒê√£ t·∫£i m√¥ h√¨nh t·ª´: {filepath}")
        return model
    
    
    def save_preprocessing_components(self, ohe, fitted_lambda, product_target_mean, 
                                     overall_mean, filename="preprocessing.joblib"):
        """
        L∆∞u c√°c th√†nh ph·∫ßn preprocessing (QUAN TR·ªåNG!)
        
        Parameters:
        -----------
        ohe : OneHotEncoder
            One-Hot Encoder ƒë√£ ƒë∆∞·ª£c fit
        fitted_lambda : float
            Lambda value t·ª´ Box-Cox transformation
        product_target_mean : dict or Series
            Target encoding mean cho c·ªôt Name
        overall_mean : float
            Mean t·ªïng th·ªÉ c·ªßa TotalDue
        filename : str
            T√™n file ƒë·ªÉ l∆∞u
        """
        preprocessing_data = {
            'ohe': ohe,
            'fitted_lambda': fitted_lambda,
            'product_target_mean': product_target_mean,
            'overall_mean': overall_mean
        }
        
        filepath = self.model_dir / filename
        joblib.dump(preprocessing_data, filepath)
        print(f"‚úÖ ƒê√£ l∆∞u preprocessing components t·∫°i: {filepath}")
    
    
    def load_preprocessing_components(self, filename="preprocessing.joblib"):
        """
        T·∫£i c√°c th√†nh ph·∫ßn preprocessing
        
        Parameters:
        -----------
        filename : str
            T√™n file c·∫ßn t·∫£i
            
        Returns:
        --------
        dict : Dictionary ch·ª©a c√°c components
        """
        filepath = self.model_dir / filename
        preprocessing_data = joblib.load(filepath)
        
        self.ohe = preprocessing_data['ohe']
        self.fitted_lambda = preprocessing_data['fitted_lambda']
        self.product_target_mean = preprocessing_data['product_target_mean']
        self.overall_mean = preprocessing_data['overall_mean']
        
        print(f"‚úÖ ƒê√£ t·∫£i preprocessing components t·ª´: {filepath}")
        return preprocessing_data
    
    
    def save_complete_pipeline(self, model, ohe, fitted_lambda, product_target_mean, 
                              overall_mean, model_name="complete_pipeline"):
        """
        L∆∞u to√†n b·ªô pipeline (m√¥ h√¨nh + preprocessing)
        
        Parameters:
        -----------
        model : object
            M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán
        ohe : OneHotEncoder
            One-Hot Encoder ƒë√£ ƒë∆∞·ª£c fit
        fitted_lambda : float
            Lambda value t·ª´ Box-Cox transformation
        product_target_mean : dict or Series
            Target encoding mean cho c·ªôt Name
        overall_mean : float
            Mean t·ªïng th·ªÉ c·ªßa TotalDue
        model_name : str
            T√™n base cho c√°c file
        """
        # L∆∞u m√¥ h√¨nh
        self.save_model_joblib(model, f"{model_name}_model.joblib")
        
        # L∆∞u preprocessing
        self.save_preprocessing_components(
            ohe, fitted_lambda, product_target_mean, overall_mean,
            f"{model_name}_preprocessing.joblib"
        )
        
        print(f"\nüéâ ƒê√£ l∆∞u to√†n b·ªô pipeline v·ªõi t√™n: {model_name}")
    
    
    def load_complete_pipeline(self, model_name="complete_pipeline"):
        """
        T·∫£i to√†n b·ªô pipeline (m√¥ h√¨nh + preprocessing)
        
        Parameters:
        -----------
        model_name : str
            T√™n base c·ªßa pipeline
            
        Returns:
        --------
        tuple : (model, preprocessing_components)
        """
        # T·∫£i m√¥ h√¨nh
        self.model = self.load_model_joblib(f"{model_name}_model.joblib")
        
        # T·∫£i preprocessing
        preprocessing = self.load_preprocessing_components(f"{model_name}_preprocessing.joblib")
        
        print(f"\nüéâ ƒê√£ t·∫£i to√†n b·ªô pipeline: {model_name}")
        return self.model, preprocessing
    
    
    def preprocess_new_data(self, new_data_df):
        """
        X·ª≠ l√Ω d·ªØ li·ªáu m·ªõi gi·ªëng nh∆∞ d·ªØ li·ªáu training
        
        Parameters:
        -----------
        new_data_df : DataFrame
            D·ªØ li·ªáu m·ªõi c·∫ßn d·ª± ƒëo√°n (ph·∫£i c√≥ c√°c c·ªôt gi·ªëng training)
            
        Returns:
        --------
        DataFrame : D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
        """
        if self.ohe is None or self.fitted_lambda is None:
            raise ValueError("‚ö†Ô∏è Ch∆∞a load preprocessing components! H√£y g·ªçi load_complete_pipeline() tr∆∞·ªõc.")
        
        df = new_data_df.copy()
        # 1. Feature Extraction: Extract date features
        if 'OrderDate' in df.columns:
            df["OrderDate"] = pd.to_datetime(df["OrderDate"])
            df["Year"] = df["OrderDate"].dt.year
            df["Month"] = df["OrderDate"].dt.month
            df["Day"] = df["OrderDate"].dt.day
            df.drop(columns=["OrderDate"], inplace=True)
        
        # 2. Fill missing values
        if "ProductLine" in df.columns:
            df["ProductLine"] = df["ProductLine"].fillna("Unidentified")
        
        # 3. Box-Cox transformation cho OrderQty
        if "OrderQty" in df.columns:
            df["OrderQty_boxcox"] = boxcox(df["OrderQty"], lmbda=self.fitted_lambda)
            df.drop(columns=["OrderQty"], inplace=True)
        
        # 4. One-Hot Encoding
        ohe_cols = ["PersonType", "ProductLine", "Name_territory", "CountryRegionCode", "Group"]
        available_ohe_cols = [col for col in ohe_cols if col in df.columns]
        
        if available_ohe_cols:
            encoded_array = self.ohe.transform(df[available_ohe_cols])
            encoded_columns = self.ohe.get_feature_names_out(input_features=available_ohe_cols)
            encoded_df = pd.DataFrame(
                encoded_array,
                columns=encoded_columns,
                index=df.index
            )
            df = pd.concat([df.drop(columns=available_ohe_cols), encoded_df], axis=1)
        
        # 5. Target Encoding cho c·ªôt Name
        if "Name" in df.columns:
            df['Name_target_encoded'] = df['Name'].map(self.product_target_mean)
            df['Name_target_encoded'].fillna(self.overall_mean, inplace=True)
            df.drop(columns=["Name"], inplace=True)
        
        return df
    
    
    def predict(self, new_data_df):
        """
        D·ª± ƒëo√°n v·ªõi d·ªØ li·ªáu m·ªõi
        
        Parameters:
        -----------
        new_data_df : DataFrame
            D·ªØ li·ªáu m·ªõi c·∫ßn d·ª± ƒëo√°n
            
        Returns:
        --------
        array : K·∫øt qu·∫£ d·ª± ƒëo√°n
        """
        if self.model is None:
            raise ValueError("‚ö†Ô∏è Ch∆∞a load m√¥ h√¨nh! H√£y g·ªçi load_complete_pipeline() tr∆∞·ªõc.")
        
        # Preprocess d·ªØ li·ªáu m·ªõi
        processed_data = self.preprocess_new_data(new_data_df)
        
        # D·ª± ƒëo√°n
        predictions = self.model.predict(processed_data)
        
        print(f"‚úÖ ƒê√£ d·ª± ƒëo√°n cho {len(predictions)} m·∫´u")
        return predictions
